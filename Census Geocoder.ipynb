{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Census Geocoder\n",
    "- This notebook reads in address data and geocodes it using the U.S. Census Geocoder (https://geocoding.geo.census.gov/geocoder/geographies/addressbatch?form).  \n",
    "\n",
    "\n",
    "- The census benchmark is set to **Public_AR_Current**.\n",
    "\n",
    "\n",
    "- Incoming data should only include the following fields.\n",
    "    - address\n",
    "    - city\n",
    "    - state (cd)\n",
    "    - zip\n",
    "\n",
    "- The notebook will create a single dataframe called **results_df** that can be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the cell below when using in alteryx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should not be needed when reading data from alteryx\n",
    "path = 'C:/Census Dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the below cell when using in Alteryx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(path + 'Census Geo_uniq addess.csv') should be changed to read the data in from alteryx. \n",
    "df = pd.read_csv(path + 'Census Geo_uniq addess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with any part of the address missing.  Addresses missing columns will not have a match.  This will reduce processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format zip code to prevent errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df. = df.zip.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Batch IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_id(data):\n",
    "    batch_sz = 9999\n",
    "    batch_id=0\n",
    "    record_ct=0\n",
    "    for index, row in data.iterrows():\n",
    "        if record_ct == batch_sz:\n",
    "            record_ct = 0 # reset record count when batch size is reached\n",
    "            \n",
    "        if record_ct == 0:\n",
    "            batch_id = batch_id + 1  #add 1 to batch ID every time record count is reset\n",
    "            \n",
    "        record_ct = record_ct + 1\n",
    "        data.at[index,'batch']=batch_id\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = create_batch_id(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below allows us to query the US Census website and geocode addresses.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_geo(data):\n",
    "    c_file = data.to_csv(header = False)\n",
    "    url = 'https://geocoding.geo.census.gov/geocoder/geographies/addressbatch'\n",
    "    payload = {'benchmark':'Public_AR_Current','vintage':'Current_Current'} \n",
    "    files = {'addressFile': ('Addresses.csv', c_file, 'text/csv')}\n",
    "    r = requests.post(url, files=files, data = payload)\n",
    "    return(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send addresses in batches through the U.S. Census Geocoder and append results to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "#create empty dataframe to hold addresses after processing.\n",
    "results_df = pd.DataFrame({'record_id':[], 'address':[], 'match/no_match':[], 'match_type':[], \n",
    "                           'geo_address':[], 'lat_long':[], 'tiger_line_id':[], \n",
    "                           'side':[], 'state_id':[], 'county_id':[], 'tract_id':[], 'block_id':[]})\n",
    "\n",
    "#identify the number of batches to be processed and use number in loop below.\n",
    "batch_ct = max(batch_df['batch'])\n",
    "\n",
    "# must define column names to prevent read_csv from thinking there are less columns than there truly are.\n",
    "names = ['record_id', 'address', 'match/no_match', 'match_type', 'geo_address', 'lat_long', 'tiger_line_id', 'side', 'state_id', 'county_id', 'tract_id','block_id']\n",
    "\n",
    "#set counter for loop\n",
    "i=1\n",
    "\n",
    "while i <= batch_ct:\n",
    "    c_file = batch_df[batch_df['batch']==batch_ct]\n",
    "    c_file = c_file.drop('batch', axis=1)\n",
    "    geo_file = get_geo(c_file)\n",
    "    results_df = results_df.append(pd.read_csv(io.StringIO(geo_file), names = names))\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
